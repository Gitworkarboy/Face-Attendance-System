\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{ref:detect-1}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}{section.1}}
\newlabel{introduction}{{I}{1}{Introduction}{section.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {I-A}}Face detection}{1}{subsection.1.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {I-B}}Landmark detection}{1}{subsection.1.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {I-C}}Face recognition}{1}{subsection.1.3}}
\@writefile{toc}{\contentsline {section}{\numberline {II}Proposed system}{2}{section.2}}
\newlabel{proposed-system}{{II}{2}{Proposed system}{section.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Model structure. Our network consists of a batch input layer and a deep CNN followed by L2 normalization, which results in the face embedding. This is followed by the triplet loss during training.\relax }}{2}{figure.caption.1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:pipeline}{{1}{2}{Model structure. Our network consists of a batch input layer and a deep CNN followed by L2 normalization, which results in the face embedding. This is followed by the triplet loss during training.\relax }{figure.caption.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {III}Implementation}{2}{section.3}}
\newlabel{implementation}{{III}{2}{Implementation}{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-A}}Motion-blur detection}{2}{subsection.3.1}}
\newlabel{motion-blur-detection}{{\unhbox \voidb@x \hbox {III-A}}{2}{Motion-blur detection}{subsection.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-B}}Face detection}{2}{subsection.3.2}}
\newlabel{face-detection}{{\unhbox \voidb@x \hbox {III-B}}{2}{Face detection}{subsection.3.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-C}}Frontal-view detection}{2}{subsection.3.3}}
\newlabel{frontal-view-detection}{{\unhbox \voidb@x \hbox {III-C}}{2}{Frontal-view detection}{subsection.3.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-D}}Face recognition}{2}{subsection.3.4}}
\newlabel{face-recognition}{{\unhbox \voidb@x \hbox {III-D}}{2}{Face recognition}{subsection.3.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Pipeline of our cascaded framework that includes three-stage multi-task deep convolutional networks. Firstly, candidate windows are produced through a fast Proposal Network (P-Net). After that, we refine these candidates in the next stage through a Refinement Network (R-Net). In the third stage, The Output Network (O-Net) produces final bounding box and facial landmarks position.\relax }}{3}{figure.caption.2}}
\newlabel{fig:mtcnn}{{2}{3}{Pipeline of our cascaded framework that includes three-stage multi-task deep convolutional networks. Firstly, candidate windows are produced through a fast Proposal Network (P-Net). After that, we refine these candidates in the next stage through a Refinement Network (R-Net). In the third stage, The Output Network (O-Net) produces final bounding box and facial landmarks position.\relax }{figure.caption.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\unhbox \voidb@x \hbox {III-D}1}Multi-task Convolution Network}{3}{figure.caption.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces The architectures of P-Net, R-Net, and O-Net, where “MP” means max pooling and “Conv” means convolution. The step size in convolution and pooling is 1 and 2, respectively\relax }}{3}{figure.caption.3}}
\newlabel{fig:mtcnn-arch}{{3}{3}{The architectures of P-Net, R-Net, and O-Net, where “MP” means max pooling and “Conv” means convolution. The step size in convolution and pooling is 1 and 2, respectively\relax }{figure.caption.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces The Triplet Loss minimizes the distance between an anchor and a positive, both of which have the same identity, and maximizes the distance between the anchor and a negative of a different identity.\relax }}{3}{figure.caption.4}}
\newlabel{fig:triplet}{{4}{3}{The Triplet Loss minimizes the distance between an anchor and a positive, both of which have the same identity, and maximizes the distance between the anchor and a negative of a different identity.\relax }{figure.caption.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\unhbox \voidb@x \hbox {III-D}2}FaceNet model}{3}{subsubsection.3.4.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\unhbox \voidb@x \hbox {III-D}3}Training}{3}{subsubsection.3.4.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Schema for Inception-ResNet-v1 and Inception-ResNet-v2 networks. This schema applies to both networks but the underlying components differ.\relax }}{4}{figure.caption.5}}
\newlabel{fig:inception-resnet}{{5}{4}{Schema for Inception-ResNet-v1 and Inception-ResNet-v2 networks. This schema applies to both networks but the underlying components differ.\relax }{figure.caption.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-E}}Graphic User Interface}{4}{subsection.3.5}}
\newlabel{gui}{{\unhbox \voidb@x \hbox {III-E}}{4}{Graphic User Interface}{subsection.3.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-F}}Attendance management}{4}{subsection.3.6}}
\newlabel{attendance-management}{{\unhbox \voidb@x \hbox {III-F}}{4}{Attendance management}{subsection.3.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces New standard excel form\relax }}{4}{figure.caption.6}}
\newlabel{fig:form-new}{{6}{4}{New standard excel form\relax }{figure.caption.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Excel form contain pre-inputed data\relax }}{4}{figure.caption.7}}
\newlabel{fig:form-data}{{7}{4}{Excel form contain pre-inputed data\relax }{figure.caption.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Experimental result}{4}{section.4}}
\newlabel{experimental-result}{{IV}{4}{Experimental result}{section.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-A}}Embedings}{4}{subsection.4.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Form is under checking\relax }}{4}{figure.caption.8}}
\newlabel{fig:form-checked}{{8}{4}{Form is under checking\relax }{figure.caption.8}{}}
\bibcite{ref:detect-1}{1}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Embeddings with PCA visualization\relax }}{5}{figure.caption.9}}
\newlabel{fig:pca}{{9}{5}{Embeddings with PCA visualization\relax }{figure.caption.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Embeddings with t-SNE visualization\relax }}{5}{figure.caption.10}}
\newlabel{fig:t-sne}{{10}{5}{Embeddings with t-SNE visualization\relax }{figure.caption.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-B}}Training}{5}{subsection.4.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Unrecognized identity, (a),(b) are training images, and (c),(d) are testing images in pratical condition.\relax }}{5}{figure.caption.11}}
\newlabel{fig:compare}{{11}{5}{Unrecognized identity, (a),(b) are training images, and (c),(d) are testing images in pratical condition.\relax }{figure.caption.11}{}}
\@writefile{toc}{\contentsline {section}{\numberline {V}Conclusion}{5}{section.5}}
\newlabel{conclusion}{{V}{5}{Conclusion}{section.5}{}}
\bibcite{ref:detect-2}{2}
\bibcite{ref:keypoint-1}{3}
\bibcite{ref:keypoint-2}{4}
\bibcite{ref:keypoint-3}{5}
\bibcite{ref:block-1}{6}
\bibcite{ref:block-2}{7}
\bibcite{ref:goh}{8}
\bibcite{ref:he}{9}
\bibcite{ref:prove-wavelet}{10}
\@writefile{toc}{\contentsline {section}{References}{6}{section*.13}}
