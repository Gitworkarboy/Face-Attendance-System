<<<<<<< HEAD
=======
<<<<<<< HEAD
>>>>>>> a18b8e17b19314c18299074418de030d02b6e16a
\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}{section.1}}
\newlabel{introduction}{{I}{1}{Introduction}{section.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {I-A}}Face detection}{1}{subsection.1.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {I-B}}Landmark detection}{1}{subsection.1.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {I-C}}Face recognition}{1}{subsection.1.3}}
\@writefile{toc}{\contentsline {section}{\numberline {II}Proposed system}{1}{section.2}}
\newlabel{proposed-system}{{II}{1}{Proposed system}{section.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces The system pipeline. There are four stages, namely blur detection, face detection, landmark detection, and face recognition. These four blocks are in the descending order of size in the direction from input to output. This points out that our system are tougher to input frames from the camera when such frames passed through the system. Therefore, best frames are likely to be processed, which may improves the final recognition accuracy.\relax }}{1}{figure.caption.1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:system}{{1}{1}{The system pipeline. There are four stages, namely blur detection, face detection, landmark detection, and face recognition. These four blocks are in the descending order of size in the direction from input to output. This points out that our system are tougher to input frames from the camera when such frames passed through the system. Therefore, best frames are likely to be processed, which may improves the final recognition accuracy.\relax }{figure.caption.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {III}Implementation}{2}{section.3}}
\newlabel{implementation}{{III}{2}{Implementation}{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-A}}Motion-blur detection}{2}{subsection.3.1}}
\newlabel{motion-blur-detection}{{\unhbox \voidb@x \hbox {III-A}}{2}{Motion-blur detection}{subsection.3.1}{}}
\newlabel{dft.eq}{{1}{2}{Motion-blur detection}{equation.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-B}}Face detection}{2}{subsection.3.2}}
\newlabel{face-detection}{{\unhbox \voidb@x \hbox {III-B}}{2}{Face detection}{subsection.3.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-C}}Frontal-view detection}{2}{subsection.3.3}}
\newlabel{frontal-view-detection}{{\unhbox \voidb@x \hbox {III-C}}{2}{Frontal-view detection}{subsection.3.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-D}}Face recognition}{2}{subsection.3.4}}
\newlabel{face-recognition}{{\unhbox \voidb@x \hbox {III-D}}{2}{Face recognition}{subsection.3.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-E}}Graphic User Interface}{2}{subsection.3.5}}
\newlabel{gui}{{\unhbox \voidb@x \hbox {III-E}}{2}{Graphic User Interface}{subsection.3.5}{}}
\bibcite{ref:keypoint-1}{1}
\bibcite{ref:keypoint-2}{2}
\bibcite{ref:keypoint-3}{3}
\bibcite{ref:block-1}{4}
\bibcite{ref:block-2}{5}
\bibcite{ref:goh}{6}
\bibcite{ref:he}{7}
\bibcite{ref:prove-wavelet}{8}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces New standard excel form\relax }}{3}{figure.caption.2}}
\newlabel{fig:form-new}{{2}{3}{New standard excel form\relax }{figure.caption.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Excel form contain pre-inputed data\relax }}{3}{figure.caption.3}}
\newlabel{fig:form-data}{{3}{3}{Excel form contain pre-inputed data\relax }{figure.caption.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-F}}Attendance management}{3}{subsection.3.6}}
\newlabel{attendance-management}{{\unhbox \voidb@x \hbox {III-F}}{3}{Attendance management}{subsection.3.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Experimental result}{3}{section.4}}
\newlabel{experimental-result}{{IV}{3}{Experimental result}{section.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Form is under checking\relax }}{3}{figure.caption.4}}
\newlabel{fig:form-checked}{{4}{3}{Form is under checking\relax }{figure.caption.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {V}Conclusion}{3}{section.5}}
\newlabel{conclusion}{{V}{3}{Conclusion}{section.5}{}}
\@writefile{toc}{\contentsline {section}{References}{3}{section*.6}}
<<<<<<< HEAD
=======
=======
\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{ref:detect-1}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}{section.1}}
\newlabel{introduction}{{I}{1}{Introduction}{section.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {I-A}}Face detection}{1}{subsection.1.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {I-B}}Landmark detection}{1}{subsection.1.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {I-C}}Face recognition}{1}{subsection.1.3}}
\@writefile{toc}{\contentsline {section}{\numberline {II}Proposed system}{2}{section.2}}
\newlabel{proposed-system}{{II}{2}{Proposed system}{section.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {III}Implementation}{2}{section.3}}
\newlabel{implementation}{{III}{2}{Implementation}{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-A}}Motion-blur detection}{2}{subsection.3.1}}
\newlabel{motion-blur-detection}{{\unhbox \voidb@x \hbox {III-A}}{2}{Motion-blur detection}{subsection.3.1}{}}
\newlabel{dft.eq}{{1}{2}{Motion-blur detection}{equation.3.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Model structure. Our network consists of a batch input layer and a deep CNN followed by L2 normalization, which results in the face embedding. This is followed by the triplet loss during training.\relax }}{3}{figure.caption.1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:pipeline}{{1}{3}{Model structure. Our network consists of a batch input layer and a deep CNN followed by L2 normalization, which results in the face embedding. This is followed by the triplet loss during training.\relax }{figure.caption.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-B}}Face detection}{3}{subsection.3.2}}
\newlabel{face-detection}{{\unhbox \voidb@x \hbox {III-B}}{3}{Face detection}{subsection.3.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-C}}Frontal-view detection}{3}{subsection.3.3}}
\newlabel{frontal-view-detection}{{\unhbox \voidb@x \hbox {III-C}}{3}{Frontal-view detection}{subsection.3.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-D}}Face recognition}{3}{subsection.3.4}}
\newlabel{face-recognition}{{\unhbox \voidb@x \hbox {III-D}}{3}{Face recognition}{subsection.3.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\unhbox \voidb@x \hbox {III-D}1}Multi-task Convolution Network}{3}{figure.caption.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Pipeline of our cascaded framework that includes three-stage multi-task deep convolutional networks. Firstly, candidate windows are produced through a fast Proposal Network (P-Net). After that, we refine these candidates in the next stage through a Refinement Network (R-Net). In the third stage, The Output Network (O-Net) produces final bounding box and facial landmarks position.\relax }}{3}{figure.caption.2}}
\newlabel{fig:mtcnn}{{2}{3}{Pipeline of our cascaded framework that includes three-stage multi-task deep convolutional networks. Firstly, candidate windows are produced through a fast Proposal Network (P-Net). After that, we refine these candidates in the next stage through a Refinement Network (R-Net). In the third stage, The Output Network (O-Net) produces final bounding box and facial landmarks position.\relax }{figure.caption.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\unhbox \voidb@x \hbox {III-D}2}FaceNet model}{3}{subsubsection.3.4.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces The architectures of P-Net, R-Net, and O-Net, where \IeC {\textquotedblleft }MP\IeC {\textquotedblright } means max pooling and \IeC {\textquotedblleft }Conv\IeC {\textquotedblright } means convolution. The step size in convolution and pooling is 1 and 2, respectively\relax }}{4}{figure.caption.3}}
\newlabel{fig:mtcnn-arch}{{3}{4}{The architectures of P-Net, R-Net, and O-Net, where “MP” means max pooling and “Conv” means convolution. The step size in convolution and pooling is 1 and 2, respectively\relax }{figure.caption.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces The Triplet Loss minimizes the distance between an anchor and a positive, both of which have the same identity, and maximizes the distance between the anchor and a negative of a different identity.\relax }}{4}{figure.caption.4}}
\newlabel{fig:triplet}{{4}{4}{The Triplet Loss minimizes the distance between an anchor and a positive, both of which have the same identity, and maximizes the distance between the anchor and a negative of a different identity.\relax }{figure.caption.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\unhbox \voidb@x \hbox {III-D}3}Training}{4}{subsubsection.3.4.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Schema for Inception-ResNet-v1 and Inception-ResNet-v2 networks. This schema applies to both networks but the underlying components differ.\relax }}{4}{figure.caption.5}}
\newlabel{fig:inception-resnet}{{5}{4}{Schema for Inception-ResNet-v1 and Inception-ResNet-v2 networks. This schema applies to both networks but the underlying components differ.\relax }{figure.caption.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-E}}Graphic User Interface}{4}{subsection.3.5}}
\newlabel{gui}{{\unhbox \voidb@x \hbox {III-E}}{4}{Graphic User Interface}{subsection.3.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-F}}Attendance management}{4}{subsection.3.6}}
\newlabel{attendance-management}{{\unhbox \voidb@x \hbox {III-F}}{4}{Attendance management}{subsection.3.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces New standard excel form\relax }}{5}{figure.caption.6}}
\newlabel{fig:form-new}{{6}{5}{New standard excel form\relax }{figure.caption.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Excel form contain pre-inputed data\relax }}{5}{figure.caption.7}}
\newlabel{fig:form-data}{{7}{5}{Excel form contain pre-inputed data\relax }{figure.caption.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Experimental result}{5}{section.4}}
\newlabel{experimental-result}{{IV}{5}{Experimental result}{section.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-A}}Embedings}{5}{subsection.4.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-B}}Training}{5}{subsection.4.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Form is under checking\relax }}{5}{figure.caption.8}}
\newlabel{fig:form-checked}{{8}{5}{Form is under checking\relax }{figure.caption.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Embeddings with PCA visualization\relax }}{5}{figure.caption.9}}
\newlabel{fig:pca}{{9}{5}{Embeddings with PCA visualization\relax }{figure.caption.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Embeddings with t-SNE visualization\relax }}{5}{figure.caption.10}}
\newlabel{fig:t-sne}{{10}{5}{Embeddings with t-SNE visualization\relax }{figure.caption.10}{}}
\bibcite{ref:detect-1}{1}
\bibcite{ref:detect-2}{2}
\bibcite{ref:detect-2}{3}
\bibcite{ref:detect-2}{4}
\bibcite{ref:detect-2}{5}
\bibcite{ref:keypoint-1}{6}
\bibcite{ref:keypoint-2}{7}
\bibcite{ref:keypoint-3}{8}
\bibcite{ref:block-1}{9}
\bibcite{ref:block-2}{10}
\bibcite{ref:goh}{11}
\bibcite{ref:he}{12}
\bibcite{ref:prove-wavelet}{13}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Unrecognized identity, (a),(b) are training images, and (c),(d) are testing images in pratical condition.\relax }}{6}{figure.caption.11}}
\newlabel{fig:compare}{{11}{6}{Unrecognized identity, (a),(b) are training images, and (c),(d) are testing images in pratical condition.\relax }{figure.caption.11}{}}
\@writefile{toc}{\contentsline {section}{\numberline {V}Conclusion}{6}{section.5}}
\newlabel{conclusion}{{V}{6}{Conclusion}{section.5}{}}
\@writefile{toc}{\contentsline {section}{References}{6}{section*.13}}
>>>>>>> ae27279d9d88ea6b7fd29ecefef8509e3aa01974
>>>>>>> a18b8e17b19314c18299074418de030d02b6e16a
